{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration properties of Apache Spark\n",
    "#sc.stop()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "\n",
    "APP_NAME = 'pyspark_python'\n",
    "MASTER = 'local[*]'\n",
    "\n",
    "conf = SparkConf().setAppName(APP_NAME)\n",
    "conf = conf.setMaster(MASTER)\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# load my own functions\n",
    "from utils.complete_missing_partitions import *\n",
    "from utils.partitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as psf\n",
    "from pyspark.sql import Window\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data for the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use month partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (  # recreate the DataFrame\n",
    "    (1, datetime(2019, 12, 2, 14, 54, 17), 49.94),\n",
    "    (1, datetime(2019, 11, 3, 8, 58, 39), 50.49),\n",
    "    (1, datetime(2019, 8, 6, 10, 44, 1), 50.24),\n",
    "    (2, datetime(2019, 8, 2, 8, 58, 39), 62.32),\n",
    "    (2, datetime(2019, 5, 4, 10, 44, 1), 65.64))\n",
    "df = spark.createDataFrame(data, schema=(\"person\", \"timestamp\", \"weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------+\n",
      "|person|          timestamp|weight|\n",
      "+------+-------------------+------+\n",
      "|     1|2019-12-02 14:54:17| 49.94|\n",
      "|     1|2019-11-03 08:58:39| 50.49|\n",
      "|     1|2019-08-06 10:44:01| 50.24|\n",
      "|     2|2019-08-02 08:58:39| 62.32|\n",
      "|     2|2019-05-04 10:44:01| 65.64|\n",
      "+------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "referece_col = 'person'\n",
    "time_col = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = complete_missing_months(df, time_col, referece_col, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort('person', 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('partition_id', create_partitions_from_df('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------------+\n",
      "|          timestamp|person|weight|partition_id|\n",
      "+-------------------+------+------+------------+\n",
      "|2019-05-01 00:00:00|     1|  null|    20190531|\n",
      "|2019-06-01 00:00:00|     1|  null|    20190630|\n",
      "|2019-07-01 00:00:00|     1|  null|    20190731|\n",
      "|2019-08-01 00:00:00|     1| 50.24|    20190831|\n",
      "|2019-09-01 00:00:00|     1|  null|    20190930|\n",
      "|2019-10-01 00:00:00|     1|  null|    20191031|\n",
      "|2019-11-01 00:00:00|     1| 50.49|    20191130|\n",
      "|2019-12-01 00:00:00|     1| 49.94|    20191231|\n",
      "|2019-05-01 00:00:00|     2| 65.64|    20190531|\n",
      "|2019-06-01 00:00:00|     2|  null|    20190630|\n",
      "|2019-07-01 00:00:00|     2|  null|    20190731|\n",
      "|2019-08-01 00:00:00|     2| 62.32|    20190831|\n",
      "|2019-09-01 00:00:00|     2|  null|    20190930|\n",
      "|2019-10-01 00:00:00|     2|  null|    20191031|\n",
      "|2019-11-01 00:00:00|     2|  null|    20191130|\n",
      "|2019-12-01 00:00:00|     2|  null|    20191231|\n",
      "+-------------------+------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('person', 'partition_id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = df.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+\n",
      "|person|weight|partition_id|\n",
      "+------+------+------------+\n",
      "|     1|  null|    20190531|\n",
      "|     1|  null|    20190630|\n",
      "|     1|  null|    20190731|\n",
      "|     1| 50.24|    20190831|\n",
      "|     1|  null|    20190930|\n",
      "|     1|  null|    20191031|\n",
      "|     1| 50.49|    20191130|\n",
      "|     1| 49.94|    20191231|\n",
      "|     2| 65.64|    20190531|\n",
      "|     2|  null|    20190630|\n",
      "|     2|  null|    20190731|\n",
      "|     2| 62.32|    20190831|\n",
      "|     2|  null|    20190930|\n",
      "|     2|  null|    20191031|\n",
      "|     2|  null|    20191130|\n",
      "|     2|  null|    20191231|\n",
      "+------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "referece_col = 'person'\n",
    "time_col     = 'partition_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = df_part.withColumn(time_col, montly_partition_YYmmdd(time_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person: long (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- partition_id: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2019, 5, 31),\n",
       " datetime.date(2019, 6, 30),\n",
       " datetime.date(2019, 7, 31),\n",
       " datetime.date(2019, 8, 31),\n",
       " datetime.date(2019, 9, 30),\n",
       " datetime.date(2019, 10, 31),\n",
       " datetime.date(2019, 11, 30),\n",
       " datetime.date(2019, 12, 31)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_intermediate_months(df_part, time_col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = complete_missing_months(df_part, time_col, referece_col, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+\n",
      "|       partition_id|person|weight|\n",
      "+-------------------+------+------+\n",
      "|2019-05-01 00:00:00|     1|  null|\n",
      "|2019-06-01 00:00:00|     1|  null|\n",
      "|2019-07-01 00:00:00|     1|  null|\n",
      "|2019-08-01 00:00:00|     1| 50.24|\n",
      "|2019-09-01 00:00:00|     1|  null|\n",
      "|2019-10-01 00:00:00|     1|  null|\n",
      "|2019-11-01 00:00:00|     1| 50.49|\n",
      "|2019-12-01 00:00:00|     1| 49.94|\n",
      "|2019-05-01 00:00:00|     2| 65.64|\n",
      "|2019-06-01 00:00:00|     2|  null|\n",
      "|2019-07-01 00:00:00|     2|  null|\n",
      "|2019-08-01 00:00:00|     2| 62.32|\n",
      "|2019-09-01 00:00:00|     2|  null|\n",
      "|2019-10-01 00:00:00|     2|  null|\n",
      "|2019-11-01 00:00:00|     2|  null|\n",
      "|2019-12-01 00:00:00|     2|  null|\n",
      "+-------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.sort('person', 'partition_id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates like integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (  # recreate the DataFrame\n",
    "    (1, 20191231, 49.94),\n",
    "    (1, 20191130, 50.49),\n",
    "    (1, 20191031, 50.24),\n",
    "    (1, 20190531, 55.24),\n",
    "    (2, 20190831, 62.32),\n",
    "    (2, 20190131, 65.64))\n",
    "df = spark.createDataFrame(data, schema=(\"person\", \"timestamp\", \"weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"timestamp\", \n",
    "                             sf.date_format(sf.to_date(sf.unix_timestamp(df['timestamp'].cast('string'), \n",
    "                              \"yyyyMMdd\").cast(\"timestamp\")), 'yyyy-MM-dd'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+\n",
      "|person| timestamp|weight|\n",
      "+------+----------+------+\n",
      "|     1|2019-12-31| 49.94|\n",
      "|     1|2019-11-30| 50.49|\n",
      "|     1|2019-10-31| 50.24|\n",
      "|     1|2019-05-31| 55.24|\n",
      "|     2|2019-08-31| 62.32|\n",
      "|     2|2019-01-31| 65.64|\n",
      "+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "referece_col = 'person'\n",
    "time_col     = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = complete_missing_months(df, time_col, referece_col, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+\n",
      "|timestamp          |person|weight|\n",
      "+-------------------+------+------+\n",
      "|2019-01-01 00:00:00|1     |null  |\n",
      "|2019-02-01 00:00:00|1     |null  |\n",
      "|2019-03-01 00:00:00|1     |null  |\n",
      "|2019-04-01 00:00:00|1     |null  |\n",
      "|2019-05-01 00:00:00|1     |55.24 |\n",
      "|2019-06-01 00:00:00|1     |null  |\n",
      "|2019-07-01 00:00:00|1     |null  |\n",
      "|2019-08-01 00:00:00|1     |null  |\n",
      "|2019-09-01 00:00:00|1     |null  |\n",
      "|2019-10-01 00:00:00|1     |50.24 |\n",
      "|2019-11-01 00:00:00|1     |50.49 |\n",
      "|2019-12-01 00:00:00|1     |49.94 |\n",
      "|2019-01-01 00:00:00|2     |65.64 |\n",
      "|2019-02-01 00:00:00|2     |null  |\n",
      "|2019-03-01 00:00:00|2     |null  |\n",
      "|2019-04-01 00:00:00|2     |null  |\n",
      "|2019-05-01 00:00:00|2     |null  |\n",
      "|2019-06-01 00:00:00|2     |null  |\n",
      "|2019-07-01 00:00:00|2     |null  |\n",
      "|2019-08-01 00:00:00|2     |62.32 |\n",
      "|2019-09-01 00:00:00|2     |null  |\n",
      "|2019-10-01 00:00:00|2     |null  |\n",
      "|2019-11-01 00:00:00|2     |null  |\n",
      "|2019-12-01 00:00:00|2     |null  |\n",
      "+-------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('person', 'timestamp').show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+\n",
      "|timestamp          |person|weight|\n",
      "+-------------------+------+------+\n",
      "|2019-01-01 00:00:00|1     |0.0   |\n",
      "|2019-02-01 00:00:00|1     |0.0   |\n",
      "|2019-03-01 00:00:00|1     |0.0   |\n",
      "|2019-04-01 00:00:00|1     |0.0   |\n",
      "|2019-05-01 00:00:00|1     |55.24 |\n",
      "|2019-06-01 00:00:00|1     |0.0   |\n",
      "|2019-07-01 00:00:00|1     |0.0   |\n",
      "|2019-08-01 00:00:00|1     |0.0   |\n",
      "|2019-09-01 00:00:00|1     |0.0   |\n",
      "|2019-10-01 00:00:00|1     |50.24 |\n",
      "|2019-11-01 00:00:00|1     |50.49 |\n",
      "|2019-12-01 00:00:00|1     |49.94 |\n",
      "|2019-01-01 00:00:00|2     |65.64 |\n",
      "|2019-02-01 00:00:00|2     |0.0   |\n",
      "|2019-03-01 00:00:00|2     |0.0   |\n",
      "|2019-04-01 00:00:00|2     |0.0   |\n",
      "|2019-05-01 00:00:00|2     |0.0   |\n",
      "|2019-06-01 00:00:00|2     |0.0   |\n",
      "|2019-07-01 00:00:00|2     |0.0   |\n",
      "|2019-08-01 00:00:00|2     |62.32 |\n",
      "|2019-09-01 00:00:00|2     |0.0   |\n",
      "|2019-10-01 00:00:00|2     |0.0   |\n",
      "|2019-11-01 00:00:00|2     |0.0   |\n",
      "|2019-12-01 00:00:00|2     |0.0   |\n",
      "+-------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).sort('person', 'timestamp').show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
