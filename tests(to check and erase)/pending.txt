Pending by priority

1. complete historical data
- by year (ready)
- for several years.

2. count duplicates columns
https://stackoverflow.com/questions/53808602/pyspark-drop-columns-that-have-same-values-in-all-rows
3. count missing partitions
4. check if df_transformation works and create data.frame
5. widgets.py
6. Basic statistics
- medidas de tendencia central, valores nmás comunes, oercentiles, relación de la distribución con respecto aun variable, mutual information, correlaciones, coeficiente de incertidumbre
- hacer una función que antes de un join chequee si las columnas claves son null (luego del join pueden desaparecer) y si la tabla tiene duplicados (se multiplica el tiempo de ejecución si esto pasa)
- groupby to aggregate on a subset of columns (arqueotipos)
- skew data functions



7.-Check the following code


from typing import List
import pyspark.sql.functions as sf
from pipeforge.common.table import Table
from pyspark.sql import DataFrame
import pandas as pd
from pyspark.sql.types import DateType
from pipeforge.utils.spark import Spark


def read_table_between_dates(table: Table, partition_name: str, init_partition: str,
                             end_partition: str) -> DataFrame:
    return table.read().where(sf.col(partition_name).between(init_partition, end_partition))


-------------------------------------------------------------------------------------------
How to perform union on two DataFrames with different amounts of columns in spark?
-------------------------------------------------------------------------------------------

def __add_missing_columns(df, missing_column_names):
    """ Add missing columns as null in the end of the columns list """
    list_missing_columns = []
    for col in missing_column_names:
        list_missing_columns.append(lit(None).alias(col))

    return df.select(df.schema.names + list_missing_columns)


def __order_and_union_d_fs(left_df, right_df, left_list_miss_cols, right_list_miss_cols):
    """ return union of data frames with ordered columns by left_df. """
    left_df_all_cols = __add_missing_columns(left_df, left_list_miss_cols)
    right_df_all_cols = __order_df_and_add_missing_cols(right_df, left_df_all_cols.schema.names,
                                                        right_list_miss_cols)
    return left_df_all_cols.union(right_df_all_cols)


def union_d_fs(left_df, right_df):
    """ Union between two dataFrames, if there is a gap of column fields,
     it will append all missing columns as nulls """
    # Check for None input
    if left_df is None:
        raise ValueError('left_df parameter should not be None')
    if right_df is None:
        raise ValueError('right_df parameter should not be None')
        # For data frames with equal columns and order- regular union
    if left_df.schema.names == right_df.schema.names:
        return left_df.union(right_df)
    else:  # Different columns
        # Save dataFrame columns name list as set
        left_df_col_list = set(left_df.schema.names)
        right_df_col_list = set(right_df.schema.names)
        # Diff columns between left_df and right_df
        right_list_miss_cols = list(left_df_col_list - right_df_col_list)
        left_list_miss_cols = list(right_df_col_list - left_df_col_list)
        return __order_and_union_d_fs(left_df, right_df, left_list_miss_cols, right_list_miss_cols)





